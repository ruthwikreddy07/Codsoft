import cv2
import numpy as np

# Load Haar Cascade for face detection
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

# Load known faces and their encodings
def load_known_faces():
    known_faces = []
    known_names = []

    # Example: Load face images and compute descriptors
    person1 = cv2.imread("known_face_1.jpg", cv2.IMREAD_GRAYSCALE)
    person1_keypoints, person1_descriptor = detect_and_compute(person1)
    known_faces.append((person1_keypoints, person1_descriptor))
    known_names.append("Person 1")

    person2 = cv2.imread("known_face_2.jpg", cv2.IMREAD_GRAYSCALE)
    person2_keypoints, person2_descriptor = detect_and_compute(person2)
    known_faces.append((person2_keypoints, person2_descriptor))
    known_names.append("Person 2")

    return known_faces, known_names

# Detect keypoints and compute descriptors using ORB
def detect_and_compute(image):
    orb = cv2.ORB_create()
    keypoints, descriptors = orb.detectAndCompute(image, None)
    return keypoints, descriptors

# Match descriptors using FLANN-based matcher
def match_faces(descriptors1, descriptors2):
    if descriptors1 is None or descriptors2 is None:
        return 1e6  # Return a high distance if descriptors are missing
    index_params = dict(algorithm=6, table_number=6, key_size=12, multi_probe_level=1)
    search_params = dict(checks=50)
    flann = cv2.FlannBasedMatcher(index_params, search_params)
    matches = flann.knnMatch(np.asarray(descriptors1, np.float32), np.asarray(descriptors2, np.float32), k=2)

    # Apply ratio test
    good_matches = []
    for m, n in matches:
        if m.distance < 0.7 * n.distance:
            good_matches.append(m)
    return len(good_matches)

# Real-time face detection and recognition
def main():
    known_faces, known_names = load_known_faces()

    # Initialize webcam
    video_capture = cv2.VideoCapture(0)

    while True:
        ret, frame = video_capture.read()
        if not ret:
            print("Failed to capture frame. Exiting.")
            break

        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Detect faces
        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))

        for (x, y, w, h) in faces:
            # Extract face region
            face_region = gray_frame[y:y + h, x:x + w]

            # Detect keypoints and compute descriptors
            keypoints, descriptors = detect_and_compute(face_region)

            # Compare with known faces
            name = "Unknown"
            max_matches = 0
            for (known_keypoints, known_descriptors), known_name in zip(known_faces, known_names):
                matches = match_faces(descriptors, known_descriptors)
                if matches > max_matches:
                    max_matches = matches
                    name = known_name

            # Draw a rectangle and label
            color = (0, 255, 0) if name != "Unknown" else (0, 0, 255)
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            cv2.putText(frame, name, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)

        # Display the frame
        cv2.imshow("Face Detection and Recognition", frame)

        # Break the loop with 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    video_capture.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
